{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from gym import spaces\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from typing import Callable, Dict, List, Tuple, Type, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3228898",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features_path = 'data/movie_features.csv'\n",
    "rating_features_path = 'data/ratings_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f19e98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>tag</th>\n",
       "      <th>encoded_movie_ids</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_embedding_glove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>comedy drama romance</td>\n",
       "      <td>['chick flick', 'revenge', 'characters', 'chic...</td>\n",
       "      <td>0</td>\n",
       "      <td>Waiting to Exhale (1995) | comedy, drama, roma...</td>\n",
       "      <td>[-3.90065998e-01  2.85064846e-01  1.03168570e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>comedy drama romance</td>\n",
       "      <td>['president', 'president', 'us president', 'wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>American President, The (1995) | comedy, drama...</td>\n",
       "      <td>[ 5.35968468e-02  2.33869895e-01  2.60694951e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Casino (1995)</td>\n",
       "      <td>crime drama</td>\n",
       "      <td>['de niro in pink', 'joe pesci', 'martin scors...</td>\n",
       "      <td>2</td>\n",
       "      <td>Casino (1995) | crime, drama | de niro in pink...</td>\n",
       "      <td>[-0.09848612 -0.4099722  -0.08234926 -0.131738...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>crime drama</td>\n",
       "      <td>['gong li', 'yimou zhang', 'zhang yimou']</td>\n",
       "      <td>3</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>[ 0.09402635  0.07983646  0.02374954 -0.276408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>crime drama</td>\n",
       "      <td>['nun', 'death row', 'capital punishment', 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Dead Man Walking (1995) | crime, drama | nun, ...</td>\n",
       "      <td>[ 2.41189212e-01 -4.62112427e-02  1.89653516e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title  \\\n",
       "0        4                           Waiting to Exhale (1995)   \n",
       "1       11                     American President, The (1995)   \n",
       "2       16                                      Casino (1995)   \n",
       "3       30  Shanghai Triad (Yao a yao yao dao waipo qiao) ...   \n",
       "4       36                            Dead Man Walking (1995)   \n",
       "\n",
       "                 genres                                                tag  \\\n",
       "0  comedy drama romance  ['chick flick', 'revenge', 'characters', 'chic...   \n",
       "1  comedy drama romance  ['president', 'president', 'us president', 'wh...   \n",
       "2           crime drama  ['de niro in pink', 'joe pesci', 'martin scors...   \n",
       "3           crime drama          ['gong li', 'yimou zhang', 'zhang yimou']   \n",
       "4           crime drama  ['nun', 'death row', 'capital punishment', 'co...   \n",
       "\n",
       "   encoded_movie_ids                                               desc  \\\n",
       "0                  0  Waiting to Exhale (1995) | comedy, drama, roma...   \n",
       "1                  1  American President, The (1995) | comedy, drama...   \n",
       "2                  2  Casino (1995) | crime, drama | de niro in pink...   \n",
       "3                  3  Shanghai Triad (Yao a yao yao dao waipo qiao) ...   \n",
       "4                  4  Dead Man Walking (1995) | crime, drama | nun, ...   \n",
       "\n",
       "                                desc_embedding_glove  \n",
       "0  [-3.90065998e-01  2.85064846e-01  1.03168570e-...  \n",
       "1  [ 5.35968468e-02  2.33869895e-01  2.60694951e-...  \n",
       "2  [-0.09848612 -0.4099722  -0.08234926 -0.131738...  \n",
       "3  [ 0.09402635  0.07983646  0.02374954 -0.276408...  \n",
       "4  [ 2.41189212e-01 -4.62112427e-02  1.89653516e-...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(movie_features_path).drop('Unnamed: 0',axis=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ed7b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>encoded_user_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3062</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002-01-16 18:10:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4308</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2002-01-16 18:17:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4339</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2002-01-16 18:21:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002-01-16 18:22:58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2002-01-16 18:24:41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp  encoded_user_ids\n",
       "0       7     3062     3.0  2002-01-16 18:10:54                 0\n",
       "1       7     4308     4.0  2002-01-16 18:17:06                 0\n",
       "2       7     4339     4.0  2002-01-16 18:21:26                 0\n",
       "3       7       16     3.0  2002-01-16 18:22:58                 0\n",
       "4       7     2028     5.0  2002-01-16 18:24:41                 0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(rating_features_path).drop('Unnamed: 0',axis=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1314d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, userId, encodedUserId, movieRating):\n",
    "        self.userId = userId\n",
    "        self.encodedUserId = encodedUserId\n",
    "        self.movieRating = movieRating\n",
    " \n",
    "    def __str__(self):\n",
    "        user_info = f\"Encoded UserId: {self.encodedUserId}\\nUserId: {self.userId}\\nMovies Rating: {self.movieRating}\\n\"\n",
    "        return user_info\n",
    "   \n",
    "    def get_user_rating(self, movie_id):\n",
    "        # df = self.movieRating[self.movieRating['movieId']==movie_id]\n",
    "        # if df and len(df)>0:\n",
    "        #     rating = df['rating'].tolist()[0]\n",
    "        # else:\n",
    "        #     return 0.0\n",
    "        for movieid, rating in self.movieRating:\n",
    "            if movie_id == movieid:\n",
    "                return rating\n",
    "        return 0.0\n",
    "       \n",
    " \n",
    "class Movie:\n",
    "    def __init__(self, movieId, encodedMovieId, title, genre, tag, desc, descEmbedding):\n",
    "        self.movieId = movieId\n",
    "        self.encodedMovieId = encodedMovieId\n",
    "        self.title = title\n",
    "        self.genre = genre\n",
    "        self.tag = tag\n",
    "        self.desc = desc\n",
    "        self.descEmbedding = descEmbedding\n",
    "   \n",
    "    def __str__(self):\n",
    "        movie_info = f\"\\nEncoded MovieId: {self.encodedMovieId}\\nMovieId: {self.movieId}\\nTitle: {self.title}\\nGenre: {self.genre}\\nTag: {self.tag}\"\n",
    "        return movie_info\n",
    "   \n",
    " \n",
    "class Recommender():\n",
    " \n",
    "    def __init__(self, movie_features_path,ratings_features_path):\n",
    "        super(Recommender, self).__init__()\n",
    "        self.movies_data,self.users_data,self.ratings_data = self.load_features(movie_features_path,\n",
    "                                                                                ratings_features_path)\n",
    "       \n",
    "        self.movies_map,self.users_map = self.get_list_of_objects(self.movies_data,\n",
    "                                                                  self.users_data)\n",
    "       \n",
    "        self.sequences = self.get_sequences(self.movies_data,self.ratings_data)  \n",
    " \n",
    "        self.state_sequences = self.get_user_sequence_combinations()\n",
    "       \n",
    " \n",
    "    def load_features(self,movie_features_path,ratings_features_path):\n",
    "        movies = pd.read_csv(movie_features_path).drop(['Unnamed: 0'], axis=1)\n",
    "        ratings = pd.read_csv(ratings_features_path).drop(['Unnamed: 0','timestamp'], axis=1)\n",
    " \n",
    "        unique_users = ratings['userId'].unique() # Get unique users\n",
    "       \n",
    "        test_size = len(unique_users)*10//100 # 10% of the users count\n",
    " \n",
    "        train_users = unique_users[: len(unique_users)-test_size] # 90% of the users is used for training\n",
    "        test_users = unique_users[len(unique_users)-test_size:]    # 10% of the users is used for testing\n",
    " \n",
    "        train_ratings = ratings[ratings['userId'].isin(train_users)] # Select from ratings only of train users\n",
    "        test_ratings = ratings[ratings['userId'].isin(test_users)] # Select from ratings only of test users\n",
    "       \n",
    "        print('Number of unique users: ', len(unique_users))\n",
    "        print('Train unique users: ', len(train_users))\n",
    "        print('Test unique users: ', len(test_users))\n",
    "       \n",
    "        print('Total ratings size: ', ratings.shape)\n",
    "        print('Train ratings size: ', train_ratings.shape)\n",
    "        print('Test ratings size: ', test_ratings.shape)\n",
    " \n",
    "        users = train_ratings.groupby(['userId','encoded_user_ids']).apply(lambda x: list(zip(x['movieId'], x['rating']))).reset_index()\n",
    "        users.rename(columns = {0:'movie_rating'}, inplace = True)\n",
    " \n",
    "        return movies, users, train_ratings\n",
    "   \n",
    "    def get_list_of_objects(self,movies_data, user_data):\n",
    "        users_map = {};movies_map = {}\n",
    "       \n",
    " \n",
    "        for row in user_data.itertuples():\n",
    "            user_id = row.userId\n",
    "            encoded_user_id = row.encoded_user_ids\n",
    "            movie_rating = row.movie_rating\n",
    "            user = User(user_id, encoded_user_id, movie_rating)\n",
    "            users_map[user_id]=user\n",
    " \n",
    "        for row in movies_data.itertuples():\n",
    "            movie_id = row.movieId\n",
    "            encoded_movie_id = row.encoded_movie_ids\n",
    "            title = row.title\n",
    "            genre = row.genres\n",
    "            tags = row.tag\n",
    "            desc = row.desc\n",
    "            desc_embedding = np.array(row.desc_embedding_glove.replace('\\n', '').replace('[', '').replace(']', '').split(), dtype=np.float64)\n",
    "            movie = Movie(movie_id, encoded_movie_id, title, genre, tags, desc, desc_embedding)\n",
    "            movies_map[movie_id]=movie\n",
    "       \n",
    "        return movies_map, users_map\n",
    "   \n",
    " \n",
    "    def get_sequences(self,moviesdf, ratingsdf):\n",
    " \n",
    "        # Assuming you have a list of all movie IDs\n",
    "        all_movies = moviesdf.movieId.unique().tolist()\n",
    "       \n",
    "        # Assuming you have encoded_user_ids in ratingsdf\n",
    "        all_users = ratingsdf.userId.unique().tolist()\n",
    " \n",
    "        user_objects = []\n",
    "   \n",
    "        for user_id in all_users:\n",
    "            user_ratings = ratingsdf[ratingsdf['userId'] == user_id]\n",
    "            # Extracting user details\n",
    "            user_details = {\n",
    "                'user_id': user_id,                \n",
    "                'ratings_df': user_ratings\n",
    "            }\n",
    "            user_movies_watched = user_ratings['movieId'].tolist()\n",
    "            user_movie_objects = []\n",
    "            for movie_id in user_movies_watched:\n",
    "                movie_details = moviesdf[moviesdf['movieId'] == movie_id]\n",
    "                # Extracting movie details\n",
    "                movie_object = {\n",
    "                    'movie_id': movie_id,\n",
    "                    'genre': movie_details['genres'].iloc[0],\n",
    "                    'tag': movie_details['tag'].iloc[0],\n",
    "                    'title': movie_details['title'].iloc[0],\n",
    "                    'desc': movie_details['desc'].iloc[0],\n",
    "                    'desc_embedding': movie_details['desc_embedding_glove'].iloc[0]\n",
    "                }\n",
    "                user_movie_objects.append(movie_object)\n",
    "            user_objects.append({\n",
    "                'user_details': user_details,\n",
    "                'movie_objects': user_movie_objects\n",
    "            })\n",
    "       \n",
    "        # Creating sequences\n",
    "        sequence_dict = {}\n",
    "       \n",
    "        for user_obj in user_objects:\n",
    "            user_id = user_obj['user_details']['user_id']\n",
    "            user_ratings = user_obj['user_details']['ratings_df']\n",
    "            movie_seq = user_ratings['movieId'].tolist()\n",
    "            # Take n as initially watched movies\n",
    "            n = 5;\n",
    "            # Take m as number of recommended movies\n",
    "            m = 5\n",
    "            # Neg pos ratio\n",
    "            k = 2\n",
    "            sequence_lst = []\n",
    "            while n + m <= len(movie_seq):\n",
    "                movie_watched_bucket = movie_seq[:n]\n",
    "                movie_to_be_watched_bucket = movie_seq[n:]\n",
    "                common_pos_samples = list(set(movie_watched_bucket).union(set(movie_to_be_watched_bucket)))\n",
    "                total_neg_samples = [mv for mv in all_movies if mv not in movie_seq]\n",
    "                # num_neg_samples = min(k * (n+m), len(total_neg_samples))\n",
    "                # selected_neg_samples = random.sample(total_neg_samples, num_neg_samples)\n",
    "                selected_mix_samples = total_neg_samples + common_pos_samples\n",
    "                random.shuffle(selected_mix_samples)\n",
    "                sequence_lst.append({'pos_samples': movie_watched_bucket,\n",
    "                                     'mix_samples': selected_mix_samples,\n",
    "                                     'next_pos_samples': movie_to_be_watched_bucket})\n",
    "                n = n + m\n",
    "            sequence_dict[user_id] = sequence_lst\n",
    " \n",
    "        # Convert sequence_dict to DataFrame\n",
    "        df = pd.DataFrame(sequence_dict.items(), columns=['user_id', 'sequences'])\n",
    " \n",
    " \n",
    "        return df\n",
    " \n",
    "    def get_user_sequence_combinations(self):\n",
    "       \n",
    "        user_seq_lst = {}\n",
    "        for indx, row in self.sequences.iterrows():    \n",
    "            user_id = row['user_id']\n",
    "            user_ob = self.users_map[user_id]\n",
    "            sequence_lst = row['sequences']\n",
    "            row_lst = []\n",
    "            for seq in sequence_lst:\n",
    "                seq_dict = {}\n",
    "                pos_neg_samples = seq['mix_samples']  \n",
    "                seq_dict['movie_indices'] = np.array([self.movies_map[movie_id].encodedMovieId for movie_id in  pos_neg_samples],dtype=\"float\")\n",
    "                seq_dict['movie_embeddings'] = np.array([self.movies_map[movie_id].descEmbedding for movie_id in pos_neg_samples],dtype=\"float\")\n",
    "                seq_dict['movie_ratings'] =  np.array([user_ob.get_user_rating(movie_id) for movie_id in pos_neg_samples],dtype=\"float\")\n",
    "                seq_dict['user_indices'] = np.array([user_ob.encodedUserId for movie_id in  pos_neg_samples],dtype=\"float\")\n",
    "                row_lst.append(seq_dict)\n",
    "            user_seq_lst[user_ob.encodedUserId] = row_lst\n",
    "       \n",
    "        return user_seq_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users:  14867\n",
      "Train unique users:  13381\n",
      "Test unique users:  1486\n",
      "Total ratings size:  (404333, 4)\n",
      "Train ratings size:  (364315, 4)\n",
      "Test ratings size:  (40018, 4)\n"
     ]
    }
   ],
   "source": [
    "recommender = Recommender(movie_features_path,rating_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca934199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "\n",
    "    def __init__(self, user_id, seq_id, rec,total_items):\n",
    "        \n",
    "        self.userIndexes = np.array(rec.state_sequences[user_id][seq_id]['user_indices'])\n",
    "        self.movieIndexes = np.array(rec.state_sequences[user_id][seq_id]['movie_indices'])\n",
    "        self.movieEmbeddings = np.array(rec.state_sequences[user_id][seq_id]['movie_embeddings'])\n",
    "        self.movieRatings = np.array(rec.state_sequences[user_id][seq_id]['movie_ratings'])        \n",
    "\n",
    "    def get_state(self):\n",
    "        observations = { \"user_indices\":self.userIndexes, \"movie_indices\":self.movieIndexes, \"movie_embeddings\":self.movieEmbeddings, \n",
    "                        \"movie_ratings\":self.movieRatings}\n",
    "        return observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationPolicyCNN(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, user_embedding_dim,\n",
    "                 movie_embedding_dim, mlp_dims, conv_out_channels, kernel_size):\n",
    "        super(RecommendationPolicyCNN, self).__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.user_embedding_dim = user_embedding_dim\n",
    "        self.movie_embedding_dim = movie_embedding_dim\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "\n",
    "        # print(\"RecommendationPolicyCNN Policy Initialized.\") \n",
    "\n",
    "        # User Embeddings\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, user_embedding_dim)\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, user_embedding_dim)\n",
    "\n",
    "        # Convolutional layer for movie embeddings\n",
    "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=conv_out_channels, kernel_size=kernel_size, stride=1, padding=(kernel_size - 1) // 2)\n",
    "\n",
    "        # GMF\n",
    "        self.gmf_fc = nn.Linear(conv_out_channels, user_embedding_dim)\n",
    "\n",
    "        # MLP\n",
    "        mlp_input_dim = user_embedding_dim + conv_out_channels  # Concatenated dimension for user and movie embeddings\n",
    "        self.mlp_fc_layers = nn.ModuleList([nn.Linear(mlp_input_dim, mlp_dims[0])])\n",
    "        for in_size, out_size in zip(mlp_dims[:-1], mlp_dims[1:]):\n",
    "            self.mlp_fc_layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        # Final prediction layer outputs a score for each movie\n",
    "        self.output_fc = nn.Linear(user_embedding_dim + mlp_dims[-1], 1)  # Adjusted to output a single score\n",
    "\n",
    "        # print(\"RecommendationPolicyCNN Policy Initialize Completed.\") \n",
    "\n",
    "    def forward(self, user_ids, movie_ids, movie_embeddings, ratings):\n",
    "\n",
    "        # print(\"RecommendationPolicyCNN Policy Forwarded.\")\n",
    "\n",
    "        user_ids = user_ids.long()\n",
    "        \n",
    "        # Get user embeddings\n",
    "        user_embed_gmf = self.user_embedding_gmf(user_ids)[0]  # Shape: [batch_size, user_embedding_dim]\n",
    "        user_embed_mlp = self.user_embedding_mlp(user_ids)\n",
    "\n",
    "        # Process movie embeddings through Conv1D\n",
    "        movie_embeddings = movie_embeddings.unsqueeze(1).float()  # Shape: [batch_size, 1, movie_embedding_dim] \n",
    "        conv_out = F.relu(self.conv1d(movie_embeddings))  # Shape after Conv1D: [batch_size, conv_out_channels, movie_embedding_dim]\n",
    " \n",
    "        # Assuming we want to collapse the last dimension to align with user_embed_gmf for element-wise multiplication\n",
    "        conv_out_flattened = conv_out.mean(dim=2)  # Averaging across the last dimension, Shape: [batch_size, conv_out_channels]\n",
    "        \n",
    "        # GMF path\n",
    "        gmf_out = self.gmf_fc(conv_out_flattened)  # Ensure this operation results in Shape: [batch_size, user_embedding_dim]\n",
    "        gmf_out = gmf_out * user_embed_gmf  # Now this should work as both tensors have a shape of [batch_size, user_embedding_dim]\n",
    " \n",
    "        # MLP path\n",
    "        mlp_input = torch.cat((user_embed_mlp, conv_out_flattened), dim=1)\n",
    "        mlp_out = mlp_input\n",
    "        for layer in self.mlp_fc_layers:\n",
    "            mlp_out = F.relu(layer(mlp_out))\n",
    "    \n",
    "        # Combine GMF and MLP outputs\n",
    "        combined_features = torch.cat((gmf_out, mlp_out), dim=1)\n",
    "        \n",
    "        output = self.output_fc(combined_features)\n",
    "\n",
    "        print('output  is ',output.shape)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "#         # Adjust scores for visited and unvisited movies\n",
    "#         # scores[ratings > 0] = float('-inf')  # Invalidate scores for visited movies        \n",
    "    \n",
    "#         # # Get top 5 unvisited movie IDs based on scores\n",
    "#         # _, top_indices = torch.topk(scores, 5)\n",
    "#         # top_movie_ids = movie_ids[top_indices]\n",
    "\n",
    "#         # # print(\"RecommendationPolicyCNN Policy Forward Complete.\")\n",
    "#         # print('top_movie_ids ',top_movie_ids)\n",
    "#         # return top_movie_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRecommendationFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    Feature extractor that adapts the input observation space to the inputs expected by RecommendationPolicyCNN.\n",
    " \n",
    "        num_users = 15000\n",
    "        num_movies = 200\n",
    "        user_embedding_dim = 8\n",
    "        movie_embedding_dim = 100\n",
    "        mlp_dims = [512, 256, 128]\n",
    "        conv_out_channels = 128\n",
    "        kernel_size = 3\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space: spaces.Dict,\n",
    "                \n",
    "                 num_users=14867, num_movies=184, user_embedding_dim=8, \n",
    "                 movie_embedding_dim=100, mlp_dims=[512,256,128], \n",
    "                 conv_out_channels=128, kernel_size=3):\n",
    "        \n",
    "        super().__init__(observation_space, features_dim=184)  # The features_dim parameter is arbitrary here\n",
    "       \n",
    "        self.recommendation_policy_cnn = RecommendationPolicyCNN(\n",
    "            num_users=num_users,\n",
    "            num_movies=num_movies,\n",
    "            user_embedding_dim=user_embedding_dim,\n",
    "            movie_embedding_dim=movie_embedding_dim,\n",
    "            mlp_dims=mlp_dims,\n",
    "            conv_out_channels=conv_out_channels,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "       \n",
    " \n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "       \n",
    "        user_indices = torch.tensor(observations[\"user_indices\"].squeeze(0),dtype=torch.float32)\n",
    "        movie_embeddings = torch.tensor(observations[\"movie_embeddings\"].squeeze(0),dtype=torch.float32)\n",
    "        movie_ratings = torch.tensor(observations[\"movie_ratings\"].squeeze(0),dtype=torch.float32)\n",
    "        movie_indices = torch.tensor(observations[\"movie_indices\"].squeeze(0),dtype=torch.float32)\n",
    "     \n",
    "        features = self.recommendation_policy_cnn(user_indices, movie_indices,movie_embeddings, movie_ratings)\n",
    "        print('features :: ',features.shape)\n",
    "        return features\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98e831-8fb8-492f-b428-b05468ccb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "# from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    \"\"\"\n",
    "    Custom Actor-Critic policy for recommendation system.\n",
    "    Outputs softmax probabilities for each of the 184 elements and returns a flattened array.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        super(CustomActorCriticPolicy, self).__init__(observation_space, action_space, lr_schedule,\n",
    "                                                      features_extractor_class=CustomRecommendationFeaturesExtractor,\n",
    "                                                      **kwargs)\n",
    "        \n",
    "        # Assuming the output of the feature extractor is [184, 1]\n",
    "     \n",
    "        self.action_net = nn.Linear(184, 184)  # Adjust the input and output sizes as needed\n",
    "\n",
    "        # The value_net estimates the value of each state\n",
    "        self.value_net = nn.Linear(184, 1)  # Assuming a similar flattening before this layer if needed\n",
    "\n",
    "    def forward(self, obs: torch.Tensor, deterministic: bool = False):\n",
    "        features = self.extract_features(obs).view(-1, 184)  # Flatten the [184, 1] features to [184]\n",
    "        action_scores = self.action_net(features)\n",
    "        \n",
    "        # Apply softmax to convert scores to probabilities\n",
    "        action_probs = F.softmax(action_scores, dim=1) \n",
    "\n",
    "       \n",
    "        action_probs_flat = action_probs.view(-1)  # Flatten the probabilities\n",
    "\n",
    "        # For the value prediction\n",
    "        values = self.value_net(features) \n",
    "\n",
    "        return action_probs_flat, values, action_scores  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8942f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    " \n",
    "class RecommenderEnv(gym.Env):\n",
    "    def __init__(self, recommender):\n",
    "        super(RecommenderEnv, self).__init__()\n",
    "        self.recommender = recommender\n",
    "        self.current_user_index = 0\n",
    "        self.current_sequence_index = 0\n",
    "        self.num_reco = 5\n",
    " \n",
    "        self.movie_embedding_dim = 100\n",
    "        self.batch_size = len(self.recommender.state_sequences[self.current_user_index][self.current_sequence_index]['movie_indices'])       \n",
    "        self.render_mode = 'human'\n",
    "\n",
    "        self.max_item_len=len(self.recommender.movies_data.movieId.unique().tolist()) \n",
    "        print(' max item len is ',self.max_item_len)\n",
    "        # Example of action and observation space definitions\n",
    "     \n",
    "        #self.action_space = spaces.MultiDiscrete(self.num_reco) # Assuming actions are selecting among movies\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.max_item_len,), dtype=np.float32)\n",
    "        #self.action_space = spaces.Box(low=np.min(y), high=np.max(y), shape=(184,), dtype=np.float32)\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"user_indices\": spaces.Box(low=0, high=len(recommender.users_map), shape=(self.max_item_len,), dtype=float),           \n",
    "            \"movie_indices\": spaces.Box(low=0, high=len(recommender.movies_map), shape=(self.max_item_len,), dtype=float),           \n",
    "            \"movie_embeddings\": spaces.Box(low=-float('inf'), high=float('inf'), shape=(self.max_item_len, self.movie_embedding_dim), dtype=float),\n",
    "            \"movie_ratings\": spaces.Box(low=0.0, high=5.0, shape=(self.max_item_len,), dtype=float)\n",
    "           \n",
    "        })\n",
    " \n",
    "        # print(\"RecommenderEnv Initizalized.\")\n",
    " \n",
    " \n",
    "    def step(self, action):\n",
    "       \n",
    "        print('Action is ', action) \n",
    "        done = False \n",
    "        # Logic to iterate through users and their sequences\n",
    "        if self.current_sequence_index < len(self.recommender.sequences) - 1:\n",
    "            self.current_sequence_index += 1\n",
    "        else:\n",
    "            self.current_user_index += 1\n",
    "            self.current_sequence_index = 0\n",
    "       \n",
    "        if self.current_user_index >= len(self.recommender.users_map):\n",
    "            done = True # End of episode       \n",
    "        # print('Actual Next Value' , actual_next_value) \n",
    "        # Placeholder for reward calculation and state update\n",
    "        reward = 0       \n",
    "        print('Reward' , reward) \n",
    "        state = self._get_current_state() \n",
    "\n",
    "        print('State ' ,state)\n",
    "\n",
    "        \n",
    "        return state, reward, done, {}\n",
    " \n",
    "    def reset(self):\n",
    "        # Reset the environment state to the beginning\n",
    "        self.current_user_index = 0\n",
    "        self.current_sequence_index = 0\n",
    "        return self._get_current_state()\n",
    "   \n",
    "    def _get_current_state(self):\n",
    "        # Implement logic to return the current state based on the current user and sequence index\n",
    "        # This is where you'd extract the current user's pos_neg_samples, ratings, and movie_embeddings       \n",
    "        # state = State(self.recommender.sequences['user_id'][self.current_user_index], self.recommender.sequences['sequences'][self.current_user_index][self.current_sequence_index], self.recommender)\n",
    "        state = State(self.current_user_index, self.current_sequence_index, self.recommender,self.max_item_len)\n",
    "        return state.get_state()\n",
    " \n",
    "    def render(self, mode='human'):\n",
    "        # Optional for visualization\n",
    "        pass\n",
    " \n",
    "    def close(self):\n",
    "        # Optional cleanup\n",
    "        pass\n",
    " \n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    " \n",
    "def make_recommender_env(num_env):\n",
    "    \"\"\"\n",
    "    Utility function for creating the vectorized environment.\n",
    " \n",
    "    :param num_env: Number of parallel environments to create.\n",
    "    :return: A vectorized Gym environment.\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        # print(\"Env Creation Initizalized.\")\n",
    "        return RecommenderEnv(recommender)\n",
    "    # Note: Removed the `env_id` parameter from the call\n",
    "    return make_vec_env(_init, n_envs=num_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae20d0f-9944-4ef3-a724-43ad7c6ddb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment and initialize the model\n",
    "env = make_recommender_env(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653ce7b-e4a6-45c6-8dd5-e16534c35922",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment and initialize the model\n",
    "env = make_recommender_env(1) \n",
    "#model = PPO(CustomActorCriticPolicy, env, verbose=1)\n",
    "model = PPO(CustomActorCriticPolicy, env, learning_rate=1e-4, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=100)\n",
    "\n",
    "# Save the model\n",
    "# model.save('ppo_recommender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee00d6f-b49a-4bd1-94ad-932ae1b87a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fb094-328e-463a-bd2f-beef751ba192",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ca4aa-2e0b-469e-b636-62b4c9970fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
